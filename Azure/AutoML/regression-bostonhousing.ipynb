{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "source": [
    "## Get the workspace"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Workspace configuration succeeded.\n"
     ]
    }
   ],
   "source": [
    "subscription_id = '95bcf3b7-9903-4d62-9b7b-00484a87a6cb'\n",
    "resource_group = 'ResearchProject'\n",
    "workspace_name = 'AutoML'\n",
    "\n",
    "try:\n",
    "    ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n",
    "    # write the details of the workspace to a configuration file to the notebook library\n",
    "    ws.write_config()\n",
    "    print(\"Workspace configuration succeeded.\")\n",
    "except:\n",
    "    print(\"Workspace not accessible.\")"
   ]
  },
  {
   "source": [
    "## Get compute"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found existing cluster, use it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "# Choose a name for your CPU cluster\n",
    "cpu_cluster_name = \"Automl-Compute\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_F2S_V2', max_nodes=3)\n",
    "    compute_target = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "source": [
    "## Load Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "\n",
    "df = pd.DataFrame(boston.data)\n",
    "df.columns = boston.feature_names\n",
    "df['PRICE'] = boston.target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT       PRICE  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CRIM</th>\n      <th>ZN</th>\n      <th>INDUS</th>\n      <th>CHAS</th>\n      <th>NOX</th>\n      <th>RM</th>\n      <th>AGE</th>\n      <th>DIS</th>\n      <th>RAD</th>\n      <th>TAX</th>\n      <th>PTRATIO</th>\n      <th>B</th>\n      <th>LSTAT</th>\n      <th>PRICE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.613524</td>\n      <td>11.363636</td>\n      <td>11.136779</td>\n      <td>0.069170</td>\n      <td>0.554695</td>\n      <td>6.284634</td>\n      <td>68.574901</td>\n      <td>3.795043</td>\n      <td>9.549407</td>\n      <td>408.237154</td>\n      <td>18.455534</td>\n      <td>356.674032</td>\n      <td>12.653063</td>\n      <td>22.532806</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>8.601545</td>\n      <td>23.322453</td>\n      <td>6.860353</td>\n      <td>0.253994</td>\n      <td>0.115878</td>\n      <td>0.702617</td>\n      <td>28.148861</td>\n      <td>2.105710</td>\n      <td>8.707259</td>\n      <td>168.537116</td>\n      <td>2.164946</td>\n      <td>91.294864</td>\n      <td>7.141062</td>\n      <td>9.197104</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.006320</td>\n      <td>0.000000</td>\n      <td>0.460000</td>\n      <td>0.000000</td>\n      <td>0.385000</td>\n      <td>3.561000</td>\n      <td>2.900000</td>\n      <td>1.129600</td>\n      <td>1.000000</td>\n      <td>187.000000</td>\n      <td>12.600000</td>\n      <td>0.320000</td>\n      <td>1.730000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.082045</td>\n      <td>0.000000</td>\n      <td>5.190000</td>\n      <td>0.000000</td>\n      <td>0.449000</td>\n      <td>5.885500</td>\n      <td>45.025000</td>\n      <td>2.100175</td>\n      <td>4.000000</td>\n      <td>279.000000</td>\n      <td>17.400000</td>\n      <td>375.377500</td>\n      <td>6.950000</td>\n      <td>17.025000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.256510</td>\n      <td>0.000000</td>\n      <td>9.690000</td>\n      <td>0.000000</td>\n      <td>0.538000</td>\n      <td>6.208500</td>\n      <td>77.500000</td>\n      <td>3.207450</td>\n      <td>5.000000</td>\n      <td>330.000000</td>\n      <td>19.050000</td>\n      <td>391.440000</td>\n      <td>11.360000</td>\n      <td>21.200000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.677083</td>\n      <td>12.500000</td>\n      <td>18.100000</td>\n      <td>0.000000</td>\n      <td>0.624000</td>\n      <td>6.623500</td>\n      <td>94.075000</td>\n      <td>5.188425</td>\n      <td>24.000000</td>\n      <td>666.000000</td>\n      <td>20.200000</td>\n      <td>396.225000</td>\n      <td>16.955000</td>\n      <td>25.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>88.976200</td>\n      <td>100.000000</td>\n      <td>27.740000</td>\n      <td>1.000000</td>\n      <td>0.871000</td>\n      <td>8.780000</td>\n      <td>100.000000</td>\n      <td>12.126500</td>\n      <td>24.000000</td>\n      <td>711.000000</td>\n      <td>22.000000</td>\n      <td>396.900000</td>\n      <td>37.970000</td>\n      <td>50.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(506, 14)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "train_data = df[100:]\n",
    "test_data = df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train shape: (406, 14)\nTest shape: (100, 14)\n"
     ]
    }
   ],
   "source": [
    "print(f'Train shape: {train_data.shape}')\n",
    "print(f'Test shape: {test_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Uploading an estimated of 2 files\n",
      "Uploading ./data\\test_data.csv\n",
      "Uploaded ./data\\test_data.csv, 1 files out of an estimated total of 2\n",
      "Uploading ./data\\train_data.csv\n",
      "Uploaded ./data\\train_data.csv, 2 files out of an estimated total of 2\n",
      "Uploaded 2 files\n"
     ]
    }
   ],
   "source": [
    "# Data source and format (Pandas (local) or TabularDataset (remote compute))\n",
    "if not os.path.isdir('data'):\n",
    "    os.mkdir('data')\n",
    "    \n",
    "# Save the train data to a csv to be uploaded to the datastore\n",
    "pd.DataFrame(train_data).to_csv(\"data/train_data.csv\", index=False)\n",
    "pd.DataFrame(test_data).to_csv(\"data/test_data.csv\", index=False)\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "ds.upload(src_dir='./data', target_path='boston', overwrite=True, show_progress=True)\n",
    "\n",
    "# Upload the training data as a tabular dataset for access during training on remote compute\n",
    "train_dataset = Dataset.Tabular.from_delimited_files(path=ds.path('boston/train_data.csv'))\n",
    "test_dataset = Dataset.Tabular.from_delimited_files(path=ds.path('boston/test_data.csv'))\n",
    "\n",
    "label = \"PRICE\""
   ]
  },
  {
   "source": [
    "## Configure Experiment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure experiment settings\n",
    "# Data featurization (automatically scaled and normalized)\n",
    "# Exit criteria\n",
    "\n",
    "automl_settings = {\n",
    "    \"experiment_timeout_hours\" : 0.3,\n",
    "    \"enable_early_stopping\" : True,\n",
    "    \"iteration_timeout_minutes\": 5,\n",
    "    \"max_concurrent_iterations\": 4,\n",
    "    \"max_cores_per_iteration\": -1,\n",
    "    \"n_cross_validations\": 2,\n",
    "    \"primary_metric\": 'r2_score',\n",
    "    \"featurization\": 'auto',\n",
    "    \"verbosity\": logging.INFO,\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(task = 'regression',\n",
    "                             debug_log = 'automl_errors.log',\n",
    "                             compute_target=compute_target,\n",
    "                             experiment_exit_score = 1,\n",
    "                             enable_onnx_compatible_models=True,\n",
    "                             training_data = train_dataset,\n",
    "                             label_column_name = label,\n",
    "                             **automl_settings\n",
    "                            )\n",
    "\n",
    "# Choose a name for experiment\n",
    "experiment_name = 'Boston_AutoML'\n",
    "experiment = Experiment(ws, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running on remote.\n",
      "No run_configuration provided, running on Automl-Compute with default configuration\n",
      "Running on remote compute: Automl-Compute\n",
      "Parent Run ID: AutoML_85845d76-6c35-4d06-b2df-014b856e9e5e\n",
      "\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "DATA GUARDRAILS: \n",
      "\n",
      "TYPE:         High cardinality feature detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
      "              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         3   MaxAbsScaler RandomForest                      0:01:02       0.8063    0.8063\n",
      "         2   SparseNormalizer XGBoostRegressor              0:00:50       0.8398    0.8398\n",
      "         1   MaxAbsScaler XGBoostRegressor                  0:00:49       0.8331    0.8398\n",
      "         0   MaxAbsScaler LightGBM                          0:00:59       0.7853    0.8398\n",
      "         4   StandardScalerWrapper XGBoostRegressor         0:01:02       0.7983    0.8398\n",
      "         5   MaxAbsScaler ElasticNet                        0:00:57       0.6918    0.8398\n",
      "         6   MinMaxScaler RandomForest                      0:00:59       0.8002    0.8398\n",
      "         7   StandardScalerWrapper XGBoostRegressor         0:00:59       0.8443    0.8443\n",
      "         8   MinMaxScaler ExtremeRandomTrees                0:00:52       0.8329    0.8443\n",
      "         9   StandardScalerWrapper ElasticNet               0:00:58       0.6888    0.8443\n",
      "        12   StandardScalerWrapper XGBoostRegressor         0:00:53       0.7110    0.8443\n",
      "        13   RobustScaler LassoLars                         0:00:52       0.6920    0.8443\n",
      "        14   MinMaxScaler ExtremeRandomTrees                0:00:56       0.8171    0.8443\n",
      "        15   MaxAbsScaler ExtremeRandomTrees                0:00:57       0.6649    0.8443\n",
      "        11   MinMaxScaler RandomForest                      0:04:43       0.8130    0.8443\n",
      "        10   MinMaxScaler RandomForest                      0:05:07       0.8259    0.8443\n",
      "        16   MinMaxScaler ExtremeRandomTrees                0:01:00       0.8425    0.8443\n",
      "        17   MaxAbsScaler ElasticNet                        0:00:56       0.6902    0.8443\n",
      "        18   MinMaxScaler RandomForest                      0:00:58       0.7707    0.8443\n",
      "        19   MaxAbsScaler RandomForest                      0:00:57       0.7924    0.8443\n",
      "        20   RobustScaler ElasticNet                        0:00:54       0.6904    0.8443\n",
      "        21   StandardScalerWrapper RandomForest             0:00:59       0.7480    0.8443\n",
      "        22   MaxAbsScaler ElasticNet                        0:00:55       0.6911    0.8443\n",
      "        23   MinMaxScaler LightGBM                          0:00:55       0.8258    0.8443\n",
      "        24   StandardScalerWrapper XGBoostRegressor         0:00:55       0.8381    0.8443\n",
      "        25   PCA XGBoostRegressor                           0:00:57       0.1277    0.8443\n",
      "        27   RobustScaler RandomForest                      0:00:33          nan    0.8443\n",
      "        28                                                  0:00:36          nan    0.8443\n",
      "        26   StandardScalerWrapper XGBoostRegressor         0:00:56       0.7951    0.8443\n",
      "        29    VotingEnsemble                                0:01:09       0.8671    0.8671\n",
      "Run(Experiment: Boston_AutoML,\n",
      "Id: AutoML_85845d76-6c35-4d06-b2df-014b856e9e5e,\n",
      "Type: automl,\n",
      "Status: Completed)\n",
      "WARNING:root:The model you attempted to retrieve requires 'azureml-train-automl-runtime' to be installed at '==1.19.0'. Please install 'azureml-train-automl-runtime==1.19.0' (e.g. `pip install azureml-train-automl-runtime==1.19.0`) and then rerun the previous command.\n"
     ]
    }
   ],
   "source": [
    "remote_run = experiment.submit(automl_config, show_output = True)\n",
    "\n",
    "print(remote_run)\n",
    "\n",
    "remote_run.wait_for_completion()\n",
    "\n",
    "best_run_customized, fitted_model_customized = remote_run.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}