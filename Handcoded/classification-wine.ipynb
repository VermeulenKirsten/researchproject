{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import uniform\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "source": [
    "## Preprocessing\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data\n",
    "\n",
    "df = pd.read_csv('../Data/wine_data.csv')\n",
    "\n",
    "print(f'{df.head(10)}\\n')\n",
    "print(f'Shape: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"Cultivar\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Dataset\n",
    "\n",
    "X = df.drop('Cultivar', axis=1).values\n",
    "y = df.Cultivar.values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "source": [
    "# Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=70, random_state=1)\n",
    "\n",
    "print(f'Shape test set: {X_test.shape}')"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalising\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "source": [
    "## Logistic Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "logreg_model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "paramaters = {'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "              'C': uniform(0.0001, 20)\n",
    "             }\n",
    "\n",
    "nmb_iterations = 50\n",
    "max_nmb_cross_validation = 10\n",
    "\n",
    "# Randomized search for the best parameters\n",
    "for nmb_cross_validation in range(max_nmb_cross_validation):\n",
    "\n",
    "    logreg = RandomizedSearchCV(estimator = logreg_model, \n",
    "                               param_distributions = paramaters,\n",
    "                               n_iter = nmb_iterations,\n",
    "                               scoring = 'accuracy',\n",
    "                               cv = nmb_cross_validation + 2,\n",
    "                               n_jobs = -1,\n",
    "                               verbose = 1)\n",
    "\n",
    "    logreg = logreg.fit(X_train, y_train)\n",
    "    \n",
    "    print(f'Best estimator: \\u001b[36;1m{logreg.best_estimator_}\\u001b[0m')\n",
    "    print(f'Best accuracy: \\u001b[32;1m{logreg.best_score_}\\u001b[0m')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(f'{classification_report(y_test, y_pred)}\\n')\n",
    "print(f'Accuracy: \\u001b[32;1m{accuracy_score(y_test, y_pred) * 100}\\u001b[0m \\n')\n",
    "print(f'Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n') "
   ]
  },
  {
   "source": [
    "## Random Forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_trees = 1000\n",
    "max_number_of_features = 2\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=number_of_trees, max_features=max_number_of_features)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "print(f'{classification_report(y_test, y_pred)}\\n')\n",
    "print(f'Accuracy: \\u001b[32;1m{accuracy_score(y_test, y_pred) * 100}\\u001b[0m \\n')\n",
    "print(f'Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n') "
   ]
  },
  {
   "source": [
    "## Ensemble methodes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaboost\n",
    "\n",
    "adaboost = AdaBoostClassifier(n_estimators=150,learning_rate=0.9)\n",
    "adaboost.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = adaboost.predict(X_test)\n",
    "\n",
    "print(f'{classification_report(y_test, y_pred)}\\n')\n",
    "print(f'Accuracy: \\u001b[32;1m{accuracy_score(y_test, y_pred) * 100}\\u001b[0m \\n')\n",
    "print(f'Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n') "
   ]
  },
  {
   "source": [
    "## Neural Network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "y_train_hot = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a neural network\n",
    "\n",
    "unique_classes = len(df.Cultivar.unique())\n",
    "input_shape = X_train.shape[1]\n",
    "\n",
    "dropoutrate = 0.5\n",
    "\n",
    "neural_network = Sequential([\n",
    "    Input(shape=(input_shape,)), \n",
    "    Dense(20, activation='relu'),\n",
    "    Dropout(dropoutrate),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dropout(dropoutrate),\n",
    "    Dense(unique_classes, activation='sigmoid')\n",
    "])\n",
    "\n",
    "neural_network.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "class_weights = compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "history = neural_network.fit(X_train, y_train_hot, epochs=epochs , batch_size=32, validation_split=0.2, class_weight=class_weights, callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot history\n",
    "\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "\n",
    "y_pred = neural_network.predict_classes(X_test)\n",
    "\n",
    "print(f'{classification_report(y_test, y_pred)}\\n')\n",
    "print(f'Accuracy: \\u001b[32;1m{accuracy_score(y_test, y_pred) * 100}\\u001b[0m \\n')\n",
    "print(f'Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}